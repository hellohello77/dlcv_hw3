# -*- coding: utf-8 -*-
"""2022dlcv_hw3_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xfj1kDK2r2hkydp_LCr5djfysclAr89N
"""

import os
import clip
import torch
from torchvision.datasets import CIFAR100
import json
import torchvision.transforms as T
from PIL import Image
from torch.utils.data import DataLoader
import csv
import matplotlib.pyplot as plt
import argparse
# Load the model
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load('ViT-B/32', device)

parser = argparse.ArgumentParser()
parser.add_argument("img_file")
parser.add_argument("label_file")
parser.add_argument("csv_file")
args = parser.parse_args()

path_to_datafile = args.img_file

class hw3_1_dataset:
    def __init__(self, filepath):
        self.filepath = filepath
        self.file_list = [file for file in os.listdir(filepath)]
        self.file_list.sort()
    
    def __len__(self):
        return len(self.file_list)
    
    def __getitem__(self, idx):
        img_path = os.path.join(self.filepath, self.file_list[idx])
        img = Image.open(img_path)
        transformed_img = preprocess(img)
        img.close()
        return transformed_img, self.file_list[idx]

# Prepare the inputs
hw3_1_source = hw3_1_dataset(path_to_datafile)
BATCH_SIZE = 128
# iterations = 300
# print(len(hw3_1_source))
source_loader = DataLoader(hw3_1_source, batch_size=BATCH_SIZE, shuffle=False)
f = open(args.label_file)
data = json.load(f)
text_inputs = torch.cat([clip.tokenize(f"a photo of a {data[c]}") for c in data]).to(device)

# Calculate features
# predict_labels = []
csvfile = open(args.csv_file, 'w', newline='')
writer = csv.writer(csvfile)
writer.writerow(['filename', 'label'])
all = 0
text_features = model.encode_text(text_inputs)
corrects = 0
# print(data[str(0)])
with torch.no_grad():
  for idx, (imgs, names) in enumerate(source_loader):
    imgs = imgs.to(device)
    image_features = model.encode_image(imgs)

    # Pick the top 5 most similar labels for the image
    image_features /= image_features.norm(dim=-1, keepdim=True)
    text_features /= text_features.norm(dim=-1, keepdim=True)
    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)
    for i in range(similarity.shape[0]):
      values, indices = similarity[i].topk(5)
      writer.writerow([names[i], indices[0].item()])